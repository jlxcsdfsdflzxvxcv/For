import NDIlib as ndi
import numpy as np
import cv2
import time
import socket
import os
import struct
import threading
import sys

LOWER_COLOR, UPPER_COLOR = [30, 125, 150], [30, 255, 255]
KERNEL_SIZE = (3, 3)
DILATING = 3
print("Head offset, for X set to 14")
print("Head offset, for Y set to 5")
aimprecisionX = int(input("Enter offset X:"))
aimprecisionY = int(input("Enter offset Y:"))
X_SPEED = int(input("Enter X:"))
Y_SPEED = 4

class mainFunction:
    def __init__(self):
        self.hardware = None
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.header = (0x12345678, 0)
        self.mtx = threading.Lock()
        self.findHardware()

    def deactivate(self):
        with self.mtx:
            self.sock = None
        return

    def findHardware(self):
        while True:
            try:
                self.sock.connect(('127.0.0.1', 6666))
                break
            except Exception as e:
                print(f"Error connecting to socket: {e}")
                exit()

    def move(self, x, y, click="0"):
        try:
            memory_data = (int(x), int(y), 0)
            self.send_packet(self.header + memory_data)
            if click != "0":
                self.shoot()
        except Exception as e:
            print("error in movement")

    def shoot(self):
        self.send_packet(self.header + (0, 0, 0x1))
        time.sleep(0.06)
        self.send_packet(self.header + (0, 0, 0x2))

    def send_packet(self, packet_data):
        packet_bytes = struct.pack('IIiii', *packet_data)
        try:
            with self.mtx:
                self.sock.sendall(packet_bytes)
                response_bytes = self.sock.recv(struct.calcsize('IIiii'))
            response_packet = struct.unpack('IIiii', response_bytes)
            return True, response_packet
        except socket.error as e:
            print("Restarting script...")
            python = sys.executable
            os.execl(python, python, *sys.argv)

mouseMovement = mainFunction()

def find_ndi_sources():
    if not ndi.initialize():
        print("Cannot run NDI")
        return []
    ndi_find = ndi.find_create_v2()
    if ndi_find is None:
        print("Cannot create NDI finder")
        return []
    time.sleep(2)
    sources = ndi.find_get_current_sources(ndi_find)
    ndi.find_destroy(ndi_find)
    return sources

def receive_ndi_stream_cropped(source_name=None,mouseMovement=mouseMovement,find_ndi_sources=find_ndi_sources,Y_SPEED=Y_SPEED,X_SPEED=X_SPEED,aimprecisionX=aimprecisionX,DILATING=DILATING,KERNEL_SIZE=KERNEL_SIZE,LOWER_COLOR=LOWER_COLOR,UPPER_COLOR=UPPER_COLOR,aimprecisionY=aimprecisionY):
    X_FOV = int(input("Enter X FOV: "))
    Y_FOV = int(input("Enter Y FOV: "))
    print("Using wider HSV range for NDI to compensate for streaming compression")
    NDI_LOWER = [29, 83, 143] #[25, 100, 130]  # Wider than MSS [30, 125, 150]
    NDI_UPPER = [73, 255, 255] #[35, 255, 255]  # Wider than MSS [30, 255, 255]
    print(f"NDI HSV range: {NDI_LOWER} to {NDI_UPPER}")
    
    if not ndi.initialize():
        print("Cannot run NDI")
        return

    sources = find_ndi_sources()
    if not sources:
        print("No NDI sources found")
        return

    print("Available NDI sources:")
    for i, source in enumerate(sources):
        print(f"  {i}: {source.ndi_name}")

    if source_name:
        selected_source = None
        for source in sources:
            if source_name in source.ndi_name:
                selected_source = source
                break
        if not selected_source:
            print(f"Source '{source_name}' not found")
            return
    else:
        selected_source = sources[0]

    print(f"Connecting to: {selected_source.ndi_name}")

    recv_create = ndi.RecvCreateV3()
    recv_create.source_to_connect_to = selected_source
    recv_create.color_format = ndi.RECV_COLOR_FORMAT_BGRX_BGRA

    ndi_recv = ndi.recv_create_v3(recv_create)
    if ndi_recv is None:
        print("Cannot create NDI receiver")
        return

    # Target locking variables
    locked_target = None
    locked_target_id = None
    target_lost_frames = 0
    MAX_LOST_FRAMES = 9999  # How many frames to wait before considering target lost
    
    # Frame retry variables
    no_frame_count = 0
    MAX_NO_FRAME_COUNT = 100  # Max consecutive failed frame attempts before reconnecting
    last_frame_time = time.time()
    FRAME_TIMEOUT = 5.0  # Seconds to wait before considering connection dead
    
    try:
        print("Receiving frames... Press 'q' to quit")
        print(f"Cropping to {X_FOV}x{Y_FOV} pixels from center")
        print("Target locking enabled - will stick to closest target until lost")
        
        while True:
            # Try to capture frame with timeout
            t, v, a, m = ndi.recv_capture_v2(ndi_recv, 0)  # 100ms timeout instead of 0
            
            if t == ndi.FRAME_TYPE_NONE:
                no_frame_count += 1
                current_time = time.time()
                
                # Check if we've been without frames for too long
                if current_time - last_frame_time > FRAME_TIMEOUT:
                    print(f"No frames received for {FRAME_TIMEOUT} seconds. Attempting to reconnect...")
                    
                    # Destroy current receiver
                    ndi.recv_destroy(ndi_recv)
                    
                    # Wait a bit
                    time.sleep(1)
                    
                    # Try to recreate receiver
                    ndi_recv = ndi.recv_create_v3(recv_create)
                    if ndi_recv is None:
                        print("Failed to recreate NDI receiver. Exiting...")
                        break
                    
                    print("Reconnected to NDI source")
                    no_frame_count = 0
                    last_frame_time = current_time
                    continue
                
                # Print status every 50 failed attempts
                if no_frame_count % 50 == 0:
                    print(f"Waiting for frames... ({no_frame_count} attempts)")
                
                # Small delay to prevent busy waiting
                time.sleep(0.001)
                continue
            
            elif t == ndi.FRAME_TYPE_VIDEO:
                # Reset frame counters - we got a frame!
                no_frame_count = 0
                last_frame_time = time.time()
                
                try:
                    # Convert NDI frame to numpy array - same approach as MSS
                    frame_array = np.frombuffer(v.data, dtype=np.uint8)
                    frame = frame_array.reshape((v.yres, v.line_stride_in_bytes // 4, 4))
                    
                    # MSS gives us BGRA, NDI gives us BGRX/BGRA - treat them the same
                    screen_array = frame.copy()

                    frame_height, frame_width = screen_array.shape[:2]
                    x_center = frame_width // 2
                    y_center = frame_height // 2
                    left = x_center - X_FOV // 2
                    top = y_center - Y_FOV // 2

                    # Crop the frame to match MSS region approach
                    cropped_frame = screen_array[top:top + Y_FOV, left:left + X_FOV]
                    
                    # Same color processing as MSS but with wider range for NDI
                    hsv = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2HSV)
                    mask = cv2.inRange(hsv, np.array(NDI_LOWER), np.array(NDI_UPPER))
                    kernel = np.ones(KERNEL_SIZE, np.uint8)
                    # Try less dilation to reduce fragmentation
                    dilated = cv2.dilate(mask, kernel, iterations=DILATING)
                    # Try morphological closing to connect broken pieces
                    closed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel, iterations=2)
                    thresh = cv2.threshold(closed, 60, 255, cv2.THRESH_BINARY)[1]
                    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

                    if contours:
                        # Filter out small contours caused by compression artifacts
                        large_contours = []
                        for contour in contours:
                            area = cv2.contourArea(contour)
                            if area > 100:  # Only keep contours larger than 100 pixels
                                large_contours.append(contour)
                        
                        if large_contours:
                            screen_center = (X_FOV // 2, Y_FOV // 2)
                            
                            # Check if we have a locked target
                            if locked_target is not None:
                                # Try to find our locked target in current contours
                                target_found = False
                                best_match = None
                                min_center_diff = float('inf')
                                
                                # Get the center of our locked target for comparison
                                locked_x, locked_y, locked_w, locked_h = cv2.boundingRect(locked_target)
                                locked_center = (locked_x + locked_w // 2, locked_y + locked_h // 2)
                                
                                for contour in large_contours:
                                    x, y, w, h = cv2.boundingRect(contour)
                                    center = (x + w // 2, y + h // 2)
                                    
                                    # Calculate distance between centers
                                    center_diff = ((center[0] - locked_center[0]) ** 2 + 
                                                 (center[1] - locked_center[1]) ** 2) ** 0.5
                                    
                                    # If this contour is close to where our locked target was
                                    if center_diff < 50:  # Threshold for considering it the same target
                                        if center_diff < min_center_diff:
                                            min_center_diff = center_diff
                                            best_match = contour
                                            target_found = True
                                
                                if target_found:
                                    # Update locked target with new contour
                                    locked_target = best_match
                                    closest_contour = best_match
                                    target_lost_frames = 0
                                else:
                                    # Target might be temporarily occluded
                                    target_lost_frames += 1
                                    if target_lost_frames > MAX_LOST_FRAMES:
                                        # Target is lost, unlock
                                        locked_target = None
                                        locked_target_id = None
                                        print("Target lost, searching for new target...")
                                    else:
                                        # Keep using last known position
                                        closest_contour = locked_target
                            
                            # If no locked target, find the closest one
                            if locked_target is None:
                                min_distance = float('inf')
                                closest_contour = None

                                for contour in large_contours:
                                    x, y, w, h = cv2.boundingRect(contour)
                                    center = (x + w // 2, y + h // 2)
                                    distance = ((center[0] - screen_center[0]) ** 2 + 
                                              (center[1] - screen_center[1]) ** 2) ** 0.5
                                    if distance < min_distance:
                                        min_distance = distance
                                        closest_contour = contour
                                
                                if closest_contour is not None:
                                    locked_target = closest_contour
                                    locked_target_id = id(closest_contour)
                                    print("New target locked!")
                            
                            if closest_contour is not None:
                                # Get bounding box
                                x, y, w, h = cv2.boundingRect(closest_contour)
                                
                                # Find the ACTUAL topmost white pixel by scanning from top
                                topmost_pixel = None
                                for scan_y in range(0, thresh.shape[0]):
                                    for scan_x in range(x, x + w):
                                        if scan_y < thresh.shape[0] and scan_x < thresh.shape[1]:
                                            if thresh[scan_y, scan_x] == 255:
                                                topmost_pixel = (scan_x, scan_y)
                                                break
                                    if topmost_pixel:
                                        break
                                
                                if topmost_pixel:
                                    cX, cY = topmost_pixel
                                    
                                    # Draw RED dot at the actual topmost point (for visual confirmation)
                                    #cv2.circle(cropped_frame, (cX, cY), radius=4, color=(0, 0, 255), thickness=-1)
                                    
                                    # Apply MSS logic with your adjustments
                                    lower_cY = cY + aimprecisionY
                                    cX = cX + aimprecisionX 
                                    
                                    x_offset = cX - screen_center[0]
                                    y_offset_calc = lower_cY - screen_center[1]
                                    
                                    # Calculate distance from crosshair to target
                                    distance_to_target = ((x_offset ** 2) + (y_offset_calc ** 2)) ** 0.5
                                    
                                    # Adaptive speed based on distance
                                    # Close range (< 20 pixels): 20% speed
                                    # Medium range (20-50 pixels): 50% speed  
                                    # Long range (> 50 pixels): 100% speed
                                    if distance_to_target < 16:
                                        speed_multiplier = 0.5
                                    else:
                                        speed_multiplier = 1.0
                                    
                                    # Apply adaptive speed
                                    adaptive_x_speed = X_SPEED * speed_multiplier
                                    adaptive_y_speed = Y_SPEED * speed_multiplier
                                    
                                    final_x = (x_offset * (adaptive_x_speed * 0.1))
                                    final_y = (y_offset_calc * (adaptive_y_speed * 0.1))

                                    # Draw BLUE outline on locked target
                                    #cv2.drawContours(cropped_frame, [closest_contour], -1, (255, 0, 0), 2)
                                    
                                    # Move the mouse
                                    mouseMovement.move(final_x, final_y)

                                    # Draw GREEN dot where we actually aim (after adjustments)
                                    dot_x = int(cX)
                                    dot_y = int(lower_cY)
                                    #cv2.circle(cropped_frame, (dot_x, dot_y), radius=3, color=(0, 255, 0), thickness=-1)
                        else:
                            # No large contours but maybe small ones
                            if locked_target is not None:
                                target_lost_frames += 1
                                if target_lost_frames > MAX_LOST_FRAMES:
                                    locked_target = None
                                    locked_target_id = None
                                    print("All targets lost")
                    else:
                        # No contours at all
                        if locked_target is not None:
                            target_lost_frames += 1
                            if target_lost_frames > MAX_LOST_FRAMES:
                                locked_target = None
                                locked_target_id = None
                                print("All targets lost")

                    # Display the current frame
                    #cv2.imshow("NDI Aimbot View", cropped_frame)
                    
                    # Show mask for debugging (optional - can comment out)
                    #cv2.imshow("Mask", thresh)
                    
                except Exception as e:
                    print(f"Error processing frame: {e}")
                finally:
                    # Always free the video frame
                    ndi.recv_free_video_v2(ndi_recv, v)

            elif t == ndi.FRAME_TYPE_AUDIO:
                ndi.recv_free_audio_v2(ndi_recv, a)

            # Check for quit key
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        print("Interrupted by user")
    except Exception as e:
        print(f"Unexpected error: {e}")
    finally:
        cv2.destroyAllWindows()
        if ndi_recv:
            ndi.recv_destroy(ndi_recv)
        ndi.destroy()


print("Finding NDI sources...")
sources = find_ndi_sources()
if sources:
    receive_ndi_stream_cropped("PC1-Screen")
else:
    print("No NDI sources found. Make sure OBS is running with NDI output enabled.")
